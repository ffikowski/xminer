{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter API Validation: Official vs TwitterAPI.io\n",
    "\n",
    "Compare tweets fetched from both APIs for the same 1-day period to validate data consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import standard libraries (fast)\nimport pandas as pd\nimport numpy as np\nimport requests\nfrom datetime import datetime, timedelta, timezone\nfrom pathlib import Path\nimport os\nimport sys\nimport time\n\nprint('Standard libraries imported')"
  },
  {
   "cell_type": "code",
   "source": "# Import tweepy (may take a moment)\nimport tweepy\nprint('Tweepy imported')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load environment and config\n# Add src to path\nsys.path.insert(0, str(Path.cwd().parent / 'src'))\n\n# Load .env manually to avoid Config.validate() issues\nfrom dotenv import load_dotenv\nload_dotenv(Path.cwd().parent / '.env')\n\n# Get API credentials directly from environment\n# Check both uppercase (new) and lowercase (old) variable names\nX_BEARER_TOKEN = os.getenv(\"X_BEARER_TOKEN\")\nTWITTERAPIIO_API_KEY = os.getenv(\"TWITTERAPIIO_API_KEY\") or os.getenv(\"twitterapiio_API_KEY\")\n\nprint('Environment loaded')\nprint(f'Official API Bearer Token: {\"SET\" if X_BEARER_TOKEN else \"NOT SET\"}')\nprint(f'TwitterAPI.io API Key: {\"SET\" if TWITTERAPIIO_API_KEY else \"NOT SET\"}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Connect to database\nfrom xminer.io.db import engine\nfrom sqlalchemy import text\n\nprint('Database connection established')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration info - just for reference\nprint('Validation method: Fetching NEW tweets using since_id')\nprint('Each user will be queried for tweets with ID > their last fetched tweet')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get sample of X profiles with their latest tweet_id (since_id)\nquery = \"\"\"\nSELECT x_user_id, username, since_id, last_tweet_date FROM (\n    SELECT DISTINCT ON (xp.x_user_id)\n        xp.x_user_id, \n        xp.username,\n        t.tweet_id as since_id,\n        t.created_at as last_tweet_date\n    FROM x_profiles xp\n    JOIN politicians_12_2025 p ON xp.username = p.username\n    LEFT JOIN tweets t ON t.username = xp.username\n    WHERE xp.x_user_id IS NOT NULL\n      AND xp.username IS NOT NULL\n    ORDER BY xp.x_user_id, t.created_at DESC NULLS LAST\n) sub\nWHERE since_id IS NOT NULL\nORDER BY RANDOM()\nLIMIT 5\n\"\"\"\n\nwith engine.connect() as conn:\n    sample_users = pd.read_sql(text(query), conn)\n\nprint(f'Sample users for comparison ({len(sample_users)}):')\nfor _, row in sample_users.iterrows():\n    print(f'  - @{row[\"username\"]} (ID: {row[\"x_user_id\"]}) | since_id: {row[\"since_id\"]} | last: {row[\"last_tweet_date\"]}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize BOTH API clients\n\n# 1. Official Twitter API (tweepy)\nofficial_client = tweepy.Client(\n    bearer_token=X_BEARER_TOKEN,\n    wait_on_rate_limit=True\n)\nprint('Official Twitter API client initialized')\n\n# 2. TwitterAPI.io client with pagination support\nclass TwitterAPIIOClient:\n    BASE_URL = \"https://api.twitterapi.io\"\n    \n    def __init__(self, api_key: str):\n        self.api_key = api_key\n        self.headers = {\"X-API-Key\": api_key}\n    \n    def get_user_tweets(self, user_id: int, max_pages: int = 5):\n        \"\"\"Fetch tweets with pagination support\"\"\"\n        url = f\"{self.BASE_URL}/twitter/user/last_tweets\"\n        all_tweets = []\n        cursor = None\n        \n        for page in range(max_pages):\n            params = {\n                \"userId\": str(user_id),\n                \"includeReplies\": \"true\"\n            }\n            if cursor:\n                params[\"cursor\"] = cursor\n            \n            response = requests.get(url, headers=self.headers, params=params)\n            response.raise_for_status()\n            data = response.json()\n            \n            data_obj = data.get('data', {})\n            tweets = data_obj.get('tweets', []) if isinstance(data_obj, dict) else []\n            all_tweets.extend(tweets)\n            \n            # Check for next page\n            if not data.get('has_next_page') or not data.get('next_cursor'):\n                break\n            cursor = data.get('next_cursor')\n            time.sleep(0.5)  # Rate limit courtesy\n        \n        return all_tweets\n\ntwitterapiio_client = TwitterAPIIOClient(TWITTERAPIIO_API_KEY)\nprint('TwitterAPI.io client initialized')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tweet fields for official API\n",
    "TWEET_FIELDS = [\n",
    "    'created_at', 'lang', 'public_metrics', 'conversation_id',\n",
    "    'in_reply_to_user_id', 'possibly_sensitive', 'source',\n",
    "    'entities', 'referenced_tweets'\n",
    "]\n",
    "\n",
    "def normalize_official_tweet(tweet, author_id: int):\n",
    "    \"\"\"Normalize tweet from official API to common format\"\"\"\n",
    "    metrics = tweet.public_metrics or {}\n",
    "    return {\n",
    "        'tweet_id': str(tweet.id),\n",
    "        'author_id': author_id,\n",
    "        'text': tweet.text,\n",
    "        'created_at': tweet.created_at,\n",
    "        'lang': tweet.lang,\n",
    "        'like_count': metrics.get('like_count', 0),\n",
    "        'reply_count': metrics.get('reply_count', 0),\n",
    "        'retweet_count': metrics.get('retweet_count', 0),\n",
    "        'quote_count': metrics.get('quote_count', 0),\n",
    "        'impression_count': metrics.get('impression_count', 0),\n",
    "        'tweet_source': tweet.source,  # Renamed to avoid conflict\n",
    "        'api_source': 'official'\n",
    "    }\n",
    "\n",
    "def parse_twitterapiio_datetime(dt_str):\n",
    "    \"\"\"Parse TwitterAPI.io datetime format\"\"\"\n",
    "    if not dt_str:\n",
    "        return None\n",
    "    try:\n",
    "        # Format: \"Sat Sep 27 09:05:04 +0000 2025\"\n",
    "        return datetime.strptime(dt_str, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "    except:\n",
    "        try:\n",
    "            return datetime.fromisoformat(dt_str.replace('Z', '+00:00'))\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def normalize_twitterapiio_tweet(tweet):\n",
    "    \"\"\"Normalize tweet from TwitterAPI.io to common format\"\"\"\n",
    "    author = tweet.get('author', {})\n",
    "    return {\n",
    "        'tweet_id': str(tweet.get('id')),\n",
    "        'author_id': author.get('id'),\n",
    "        'text': tweet.get('text'),\n",
    "        'created_at': parse_twitterapiio_datetime(tweet.get('createdAt')),\n",
    "        'lang': tweet.get('lang'),\n",
    "        'like_count': tweet.get('likeCount', 0),\n",
    "        'reply_count': tweet.get('replyCount', 0),\n",
    "        'retweet_count': tweet.get('retweetCount', 0),\n",
    "        'quote_count': tweet.get('quoteCount', 0),\n",
    "        'impression_count': tweet.get('viewCount', 0),\n",
    "        'tweet_source': tweet.get('source'),\n",
    "        'api_source': 'twitterapiio'\n",
    "    }\n",
    "\n",
    "print('Normalization functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Fetch NEW tweets from BOTH APIs for each sample user (using since_id)\nresults = []\n\nfor idx, user in sample_users.iterrows():\n    user_id = int(user['x_user_id'])\n    username = user['username']\n    since_id = str(user['since_id'])\n    last_tweet_date = user['last_tweet_date']\n    \n    print(f'\\n{\"=\"*60}')\n    print(f'[{idx+1}/{len(sample_users)}] Fetching NEW tweets for @{username}')\n    print(f'  User ID: {user_id}')\n    print(f'  Since ID: {since_id} (last tweet: {last_tweet_date})')\n    print(f'{\"=\"*60}')\n    \n    official_tweets = []\n    twitterapiio_tweets = []\n    official_error = None\n    twitterapiio_error = None\n    \n    # 1. Fetch from Official API (using since_id)\n    print('\\n[Official Twitter API]')\n    try:\n        response = official_client.get_users_tweets(\n            id=user_id,\n            max_results=100,\n            since_id=since_id,  # Only get tweets newer than this\n            tweet_fields=TWEET_FIELDS\n        )\n        if response.data:\n            official_tweets = [normalize_official_tweet(t, user_id) for t in response.data]\n            print(f'  Retrieved: {len(official_tweets)} NEW tweets')\n            if official_tweets:\n                dates = [t['created_at'] for t in official_tweets if t['created_at']]\n                if dates:\n                    print(f'  Date range: {min(dates)} to {max(dates)}')\n        else:\n            print('  Retrieved: 0 NEW tweets')\n    except Exception as e:\n        official_error = str(e)\n        print(f'  Error: {e}')\n    \n    # 2. Fetch from TwitterAPI.io (filter by since_id client-side)\n    print('\\n[TwitterAPI.io]')\n    try:\n        tweets_raw = twitterapiio_client.get_user_tweets(user_id)\n        print(f'  Total from API: {len(tweets_raw)} tweets')\n        \n        # Filter to only tweets with ID > since_id\n        since_id_int = int(since_id)\n        for t in tweets_raw:\n            tweet_id = t.get('id')\n            if tweet_id and int(tweet_id) > since_id_int:\n                normalized = normalize_twitterapiio_tweet(t)\n                twitterapiio_tweets.append(normalized)\n        \n        print(f'  NEW tweets (ID > since_id): {len(twitterapiio_tweets)}')\n        if twitterapiio_tweets:\n            dates = [t['created_at'] for t in twitterapiio_tweets if t['created_at']]\n            if dates:\n                print(f'  Date range: {min(dates)} to {max(dates)}')\n    except Exception as e:\n        twitterapiio_error = str(e)\n        print(f'  Error: {e}')\n    \n    results.append({\n        'username': username,\n        'user_id': user_id,\n        'since_id': since_id,\n        'official_tweets': official_tweets,\n        'twitterapiio_tweets': twitterapiio_tweets,\n        'official_count': len(official_tweets),\n        'twitterapiio_count': len(twitterapiio_tweets),\n        'official_error': official_error,\n        'twitterapiio_error': twitterapiio_error\n    })\n\nprint(f'\\n{\"=\"*60}')\nprint('Fetch complete!')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create summary comparison\nprint('\\n' + '='*80)\nprint('API COMPARISON SUMMARY - NEW TWEETS ONLY')\nprint('='*80)\nprint(f'Method: Fetching tweets with ID > since_id (last fetched tweet)')\nprint(f'Sample size: {len(results)} users\\n')\n\nsummary_data = []\nfor r in results:\n    summary_data.append({\n        'Username': f\"@{r['username']}\",\n        'Since ID': r['since_id'][-8:] + '...',  # Show last 8 chars\n        'Official': r['official_count'],\n        'TwitterAPI.io': r['twitterapiio_count'],\n        'Diff': r['official_count'] - r['twitterapiio_count'],\n        'Off Err': 'Yes' if r['official_error'] else '',\n        'TIO Err': 'Yes' if r['twitterapiio_error'] else ''\n    })\n\ndf_summary = pd.DataFrame(summary_data)\nprint(df_summary.to_string(index=False))\n\nprint(f'\\n{\"-\"*40}')\nprint(f'TOTALS (NEW tweets only):')\nprint(f'  Official API:   {df_summary[\"Official\"].sum()} tweets')\nprint(f'  TwitterAPI.io:  {df_summary[\"TwitterAPI.io\"].sum()} tweets')\nprint(f'  Net Difference: {df_summary[\"Diff\"].sum()}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed comparison: Match tweets by ID\n",
    "print('\\n' + '='*80)\n",
    "print('DETAILED TWEET-BY-TWEET COMPARISON')\n",
    "print('='*80)\n",
    "\n",
    "for r in results:\n",
    "    if r['official_count'] == 0 and r['twitterapiio_count'] == 0:\n",
    "        print(f'\\n@{r[\"username\"]}: No tweets from either API')\n",
    "        continue\n",
    "    \n",
    "    print(f'\\n@{r[\"username\"]}')\n",
    "    print('-' * 40)\n",
    "    \n",
    "    # Create sets of tweet IDs\n",
    "    official_ids = {t['tweet_id'] for t in r['official_tweets']}\n",
    "    twitterapiio_ids = {t['tweet_id'] for t in r['twitterapiio_tweets']}\n",
    "    \n",
    "    common = official_ids & twitterapiio_ids\n",
    "    only_official = official_ids - twitterapiio_ids\n",
    "    only_twitterapiio = twitterapiio_ids - official_ids\n",
    "    \n",
    "    print(f'  Tweets in BOTH APIs:      {len(common)}')\n",
    "    print(f'  Only in Official API:     {len(only_official)}')\n",
    "    print(f'  Only in TwitterAPI.io:    {len(only_twitterapiio)}')\n",
    "    \n",
    "    # Show tweets only in one API\n",
    "    if only_official:\n",
    "        print(f'\\n  Tweets ONLY in Official API:')\n",
    "        for tid in list(only_official)[:2]:\n",
    "            tweet = next(t for t in r['official_tweets'] if t['tweet_id'] == tid)\n",
    "            text_preview = tweet['text'][:60] + '...' if len(tweet['text']) > 60 else tweet['text']\n",
    "            print(f'    - {tid}: \"{text_preview}\"')\n",
    "    \n",
    "    if only_twitterapiio:\n",
    "        print(f'\\n  Tweets ONLY in TwitterAPI.io:')\n",
    "        for tid in list(only_twitterapiio)[:2]:\n",
    "            tweet = next(t for t in r['twitterapiio_tweets'] if t['tweet_id'] == tid)\n",
    "            text_preview = tweet['text'][:60] + '...' if len(tweet['text']) > 60 else tweet['text']\n",
    "            print(f'    - {tid}: \"{text_preview}\"')\n",
    "    \n",
    "    # Compare metrics for common tweets\n",
    "    if common:\n",
    "        print(f'\\n  Metric comparison for matching tweets:')\n",
    "        for tweet_id in list(common)[:2]:  # Compare first 2\n",
    "            off_tweet = next(t for t in r['official_tweets'] if t['tweet_id'] == tweet_id)\n",
    "            tio_tweet = next(t for t in r['twitterapiio_tweets'] if t['tweet_id'] == tweet_id)\n",
    "            \n",
    "            text_preview = off_tweet['text'][:50] + '...' if len(off_tweet['text']) > 50 else off_tweet['text']\n",
    "            print(f'\\n    Tweet: \"{text_preview}\"')\n",
    "            print(f'    ID: {tweet_id}')\n",
    "            print(f'                   Official  |  TwitterAPI.io  |  Diff')\n",
    "            print(f'    Likes:         {off_tweet[\"like_count\"]:>8}  |  {tio_tweet[\"like_count\"]:>13}  |  {off_tweet[\"like_count\"] - tio_tweet[\"like_count\"]:>5}')\n",
    "            print(f'    Retweets:      {off_tweet[\"retweet_count\"]:>8}  |  {tio_tweet[\"retweet_count\"]:>13}  |  {off_tweet[\"retweet_count\"] - tio_tweet[\"retweet_count\"]:>5}')\n",
    "            print(f'    Impressions:   {off_tweet[\"impression_count\"]:>8}  |  {tio_tweet[\"impression_count\"]:>13}  |  {off_tweet[\"impression_count\"] - tio_tweet[\"impression_count\"]:>5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Calculate overall match statistics\nprint('\\n' + '='*80)\nprint('OVERALL VALIDATION STATISTICS')\nprint('='*80)\n\ntotal_official = 0\ntotal_twitterapiio = 0\ntotal_common = 0\ntotal_only_official = 0\ntotal_only_twitterapiio = 0\n\nfor r in results:\n    official_ids = {t['tweet_id'] for t in r['official_tweets']}\n    twitterapiio_ids = {t['tweet_id'] for t in r['twitterapiio_tweets']}\n    \n    total_official += len(official_ids)\n    total_twitterapiio += len(twitterapiio_ids)\n    total_common += len(official_ids & twitterapiio_ids)\n    total_only_official += len(official_ids - twitterapiio_ids)\n    total_only_twitterapiio += len(twitterapiio_ids - official_ids)\n\nprint(f'\\nMethod: NEW tweets only (ID > since_id)')\nprint(f'Users sampled: {len(results)}')\nprint(f'\\nTweets from Official API:     {total_official}')\nprint(f'Tweets from TwitterAPI.io:    {total_twitterapiio}')\nprint(f'\\nTweets in BOTH APIs:          {total_common}')\nprint(f'Only in Official API:         {total_only_official}')\nprint(f'Only in TwitterAPI.io:        {total_only_twitterapiio}')\n\nprint(f'\\n--- Match Rates ---')\nif total_official > 0:\n    official_match = (total_common / total_official) * 100\n    print(f'Official tweets also in TIO:  {official_match:.1f}%')\n\nif total_twitterapiio > 0:\n    tio_match = (total_common / total_twitterapiio) * 100\n    print(f'TIO tweets also in Official:  {tio_match:.1f}%')\n\nall_unique = total_common + total_only_official + total_only_twitterapiio\nif all_unique > 0:\n    overlap = (total_common / all_unique) * 100\n    print(f'Overall overlap rate:         {overlap:.1f}%')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize comparison\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfig = make_subplots(\n    rows=1, cols=2,\n    subplot_titles=['NEW Tweet Count by User', 'Overall Tweet Coverage'],\n    specs=[[{'type': 'bar'}, {'type': 'pie'}]]\n)\n\n# Bar chart: tweets per user\nusernames = [f\"@{r['username']}\" for r in results]\nofficial_counts = [r['official_count'] for r in results]\ntwitterapiio_counts = [r['twitterapiio_count'] for r in results]\n\nfig.add_trace(\n    go.Bar(name='Official API', x=usernames, y=official_counts, marker_color='#1DA1F2'),\n    row=1, col=1\n)\nfig.add_trace(\n    go.Bar(name='TwitterAPI.io', x=usernames, y=twitterapiio_counts, marker_color='#FF6B6B'),\n    row=1, col=1\n)\n\n# Pie chart: overlap\nfig.add_trace(\n    go.Pie(\n        labels=['Both APIs', 'Only Official', 'Only TwitterAPI.io'],\n        values=[total_common, total_only_official, total_only_twitterapiio],\n        marker_colors=['#2ECC71', '#1DA1F2', '#FF6B6B'],\n        textinfo='label+percent+value'\n    ),\n    row=1, col=2\n)\n\nfig.update_layout(\n    title=f'API Validation: NEW Tweets (since_id) - {len(results)} users',\n    barmode='group',\n    height=500,\n    showlegend=True\n)\n\nfig.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results to CSV\n",
    "all_tweets_data = []\n",
    "\n",
    "for r in results:\n",
    "    for t in r['official_tweets']:\n",
    "        t['username'] = r['username']\n",
    "        all_tweets_data.append(t.copy())\n",
    "    \n",
    "    for t in r['twitterapiio_tweets']:\n",
    "        t['username'] = r['username']\n",
    "        all_tweets_data.append(t.copy())\n",
    "\n",
    "if all_tweets_data:\n",
    "    df_all = pd.DataFrame(all_tweets_data)\n",
    "    output_path = Path('../outputs/api_validation_tweets.csv')\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_all.to_csv(output_path, index=False)\n",
    "    print(f'Saved {len(df_all)} tweet records to {output_path}')\n",
    "    print(f'  - Official API tweets: {len([t for t in all_tweets_data if t[\"api_source\"] == \"official\"])}')\n",
    "    print(f'  - TwitterAPI.io tweets: {len([t for t in all_tweets_data if t[\"api_source\"] == \"twitterapiio\"])}')\n",
    "else:\n",
    "    print('No tweets to save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Guide\n",
    "\n",
    "### What the metrics mean:\n",
    "- **Tweets in BOTH APIs**: These tweets were returned by both APIs - high confidence data\n",
    "- **Only in Official API**: Tweets the official API returned but TwitterAPI.io missed\n",
    "- **Only in TwitterAPI.io**: Tweets TwitterAPI.io returned but official API missed\n",
    "\n",
    "### Expected outcomes:\n",
    "- **High overlap (>90%)**: Both APIs are returning consistent data\n",
    "- **Metric differences**: Small differences in engagement counts are normal due to API timing\n",
    "- **Missing tweets**: May be due to API pagination limits or timing of data availability\n",
    "\n",
    "### Recommendations:\n",
    "- If Official API has more tweets: Use it as primary source\n",
    "- If TwitterAPI.io has more tweets: May have better historical coverage\n",
    "- For engagement metrics: Use most recent fetch regardless of source"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}