{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Analysis for Political Topics\n",
    "\n",
    "This notebook analyzes tweet mentions of specific keywords by party and creates visualizations.\n",
    "\n",
    "**Example use case:** Analyzing how different parties discuss \"Venezuela\", \"Ukraine\", \"Klimawandel\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Database connection\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "from xminer.io.db import engine\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- Load parameters from config ---\nPARAMS_FILE = Path(\"../src/xminer/config/parameters.yml\")\nassert PARAMS_FILE.exists(), f\"parameters.yml not found: {PARAMS_FILE}\"\n\nwith PARAMS_FILE.open(\"r\", encoding=\"utf-8\") as f:\n    params = yaml.safe_load(f) or {}\n\nYEAR = int(params.get(\"year\", 2025))\nMONTH = int(params.get(\"month\", 12))\nYM = f\"{YEAR:04d}{MONTH:02d}\"\n\n# Politicians table - use latest available (December 2025) since January 2026 doesn't exist yet\n# This is separate from the display period\nPOLITICIANS_YEAR = 2025\nPOLITICIANS_MONTH = 12\nPOLITICIANS_TABLE = f\"politicians_{POLITICIANS_MONTH:02d}_{POLITICIANS_YEAR}\"\n\n# Bilingual stand text (shows the data period, not the politicians table)\nSTAND_TEXT_DE = f\"Erhoben für {MONTH:02d}/{YEAR}\"\nSTAND_TEXT_EN = f\"Data from {MONTH:02d}/{YEAR}\"\n\ndef get_stand_text(language='de'):\n    return STAND_TEXT_DE if language == 'de' else STAND_TEXT_EN\n\n# Output directory for graphics\nGRAPHICS_BASE_DIR = Path(\n    params.get(\n        \"graphics_base_dir\",\n        \"../outputs\",\n    )\n)\n\nGRAPHICS_DIR = GRAPHICS_BASE_DIR / YM / \"graphics\" / \"keywords\"\nGRAPHICS_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(f\"Graphics will be saved to: {GRAPHICS_DIR}\")\nprint(f\"Display period: {YEAR}-{MONTH:02d}\")\nprint(f\"Politicians table: {POLITICIANS_TABLE}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Party colors (consistent with other notebooks)\n",
    "PARTY_COLORS = {\n",
    "    \"CDU/CSU\": \"#000000\",\n",
    "    \"CDU\": \"#000000\",\n",
    "    \"CSU\": \"#000000\",\n",
    "    \"SPD\": \"#E3000F\",\n",
    "    \"GRÜNE\": \"#1AA64A\",\n",
    "    \"BÜNDNIS 90/DIE GRÜNEN\": \"#1AA64A\",\n",
    "    \"DIE LINKE.\": \"#BE3075\",\n",
    "    \"LINKE\": \"#BE3075\",\n",
    "    \"FDP\": \"#FFED00\",\n",
    "    \"AFD\": \"#009EE0\",\n",
    "    \"BSW\": \"#009688\",\n",
    "    \"FW\": \"#F28F00\",\n",
    "    \"SSW\": \"#00A3E0\",\n",
    "}\n",
    "\n",
    "def normalize_party(p: str) -> str:\n",
    "    \"\"\"Normalize party names for consistency.\"\"\"\n",
    "    if p is None:\n",
    "        return \"\"\n",
    "    key = str(p).strip().upper()\n",
    "    \n",
    "    if key in {\"CDU\", \"CSU\"}:\n",
    "        return \"CDU/CSU\"\n",
    "    if key.startswith(\"GRÜN\") or \"GRUENE\" in key or \"B90\" in key or \"BÜNDNIS\" in key:\n",
    "        return \"GRÜNE\"\n",
    "    if key in {\"LINKE\", \"DIE LINKE\", \"DIE LINKE.\"}:\n",
    "        return \"DIE LINKE.\"\n",
    "    return key\n",
    "\n",
    "def get_party_color(party: str) -> str:\n",
    "    \"\"\"Get color for a party.\"\"\"\n",
    "    normalized = normalize_party(party)\n",
    "    return PARTY_COLORS.get(normalized, \"#888888\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Keywords to Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define keywords to search for (case-insensitive)\n# You can modify this list to analyze different topics\nKEYWORDS = [\n    \"Grönland\",\n    \"Greenland\", \n    \"Venezuela\",\n    \"Ukraine\",\n    \"Klimawandel\",\n    \"Migration\",\n]\n\n# Or analyze a single keyword in detail\n# For Greenland, we search for both German and English variants\nSINGLE_KEYWORD = \"Grönland\"  # Primary keyword for detailed analysis\nSINGLE_KEYWORD_VARIANTS = [\"Grönland\", \"Greenland\", \"Groenland\"]  # All variants to include\n\nprint(f\"Will analyze keywords: {KEYWORDS}\")\nprint(f\"\\nDetailed analysis for: {SINGLE_KEYWORD}\")\nprint(f\"Including variants: {SINGLE_KEYWORD_VARIANTS}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Keyword Analysis (e.g., Venezuela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query for single keyword by party (including all variants)\n# Build WHERE clause for all variants\nvariant_conditions = \" OR \".join([f\"t.text ILIKE '%{v}%'\" for v in SINGLE_KEYWORD_VARIANTS])\n\nquery = f\"\"\"\nSELECT \n    p.partei_kurz AS party,\n    COUNT(*) AS tweet_count,\n    COUNT(DISTINCT t.username) AS user_count,\n    SUM(t.like_count) AS total_likes,\n    SUM(t.retweet_count) AS total_retweets,\n    SUM(t.impression_count) AS total_impressions,\n    AVG(t.like_count) AS avg_likes,\n    AVG(t.impression_count) AS avg_impressions\nFROM public.tweets t\nJOIN {POLITICIANS_TABLE} p ON LOWER(t.username) = LOWER(p.username)\nWHERE {variant_conditions}\nGROUP BY p.partei_kurz\nORDER BY tweet_count DESC\n\"\"\"\n\nprint(f\"Searching for: {' OR '.join(SINGLE_KEYWORD_VARIANTS)}\")\n\nwith engine.connect() as conn:\n    df_keyword = pd.read_sql(text(query), conn)\n\n# Normalize party names\ndf_keyword['party_norm'] = df_keyword['party'].apply(normalize_party)\n\n# Aggregate by normalized party\ndf_keyword_agg = (\n    df_keyword.groupby('party_norm')\n    .agg({\n        'tweet_count': 'sum',\n        'user_count': 'sum',\n        'total_likes': 'sum',\n        'total_retweets': 'sum',\n        'total_impressions': 'sum',\n        'avg_likes': 'mean',\n        'avg_impressions': 'mean'\n    })\n    .reset_index()\n    .sort_values('tweet_count', ascending=False)\n)\n\nprint(f\"\\nTweets mentioning '{SINGLE_KEYWORD}' (all variants) by party:\")\nprint(df_keyword_agg[['party_norm', 'tweet_count', 'user_count', 'total_impressions']])\nprint(f\"\\nTotal tweets: {df_keyword_agg['tweet_count'].sum()}\")\nprint(f\"Total impressions: {df_keyword_agg['total_impressions'].sum():,.0f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create bar chart for single keyword (bilingual)\ndef create_keyword_bar_chart(df, keyword, metric='tweet_count', title=None, language='de'):\n    \"\"\"\n    Create horizontal bar chart showing party engagement with a keyword.\n    Supports 'de' (German) and 'en' (English) languages.\n    \"\"\"\n    df_sorted = df.sort_values(metric, ascending=True).copy()\n    \n    colors = [get_party_color(party) for party in df_sorted['party_norm']]\n    \n    # Metric labels (bilingual)\n    if language == 'de':\n        metric_labels = {\n            'tweet_count': 'Anzahl Tweets',\n            'total_impressions': 'Gesamte Impressionen',\n            'total_likes': 'Gesamte Likes',\n            'user_count': 'Anzahl Nutzer'\n        }\n        default_title = f\"Tweets über '{keyword}' nach Partei\"\n    else:\n        metric_labels = {\n            'tweet_count': 'Number of Tweets',\n            'total_impressions': 'Total Impressions',\n            'total_likes': 'Total Likes',\n            'user_count': 'Number of Users'\n        }\n        default_title = f\"Tweets about '{keyword}' by Party\"\n    \n    metric_label = metric_labels.get(metric, metric)\n    \n    if title is None:\n        title = default_title\n    \n    fig = go.Figure()\n    \n    fig.add_trace(go.Bar(\n        y=df_sorted['party_norm'],\n        x=df_sorted[metric],\n        orientation='h',\n        marker_color=colors,\n        text=[f\"{v:,.0f}\" for v in df_sorted[metric]],\n        textposition='outside',\n        textfont=dict(color='white', size=14),\n        hovertemplate=(\n            \"<b>%{y}</b><br>\"\n            f\"{metric_label}: %{{x:,.0f}}<br>\"\n            \"<extra></extra>\"\n        )\n    ))\n    \n    stand_text = get_stand_text(language)\n    title_text = f\"{title}<br><sub style='font-size:0.85em;'>{stand_text}</sub>\"\n    \n    fig.update_layout(\n        title=dict(text=title_text, x=0.5, xanchor='center', font=dict(size=22)),\n        xaxis_title=metric_label,\n        yaxis_title=\"\",\n        plot_bgcolor='#1a1a1a',\n        paper_bgcolor='#1a1a1a',\n        font=dict(color='white', size=14),\n        margin=dict(l=120, r=100, t=120, b=60),\n        height=max(400, 60 * len(df_sorted)),\n        xaxis=dict(gridcolor='#333333'),\n        yaxis=dict(gridcolor='#333333', tickfont=dict(size=16))\n    )\n    \n    return fig\n\n# Create charts for tweet count in both languages\nfig_tweets_de = create_keyword_bar_chart(df_keyword_agg, SINGLE_KEYWORD, metric='tweet_count', language='de')\nfig_tweets_en = create_keyword_bar_chart(df_keyword_agg, SINGLE_KEYWORD, metric='tweet_count', language='en')\n\n# Save both versions\nsave_path_de = GRAPHICS_DIR / f\"{SINGLE_KEYWORD.lower()}_tweets_by_party_de.png\"\nsave_path_en = GRAPHICS_DIR / f\"{SINGLE_KEYWORD.lower()}_tweets_by_party_en.png\"\nfig_tweets_de.write_image(save_path_de, width=1200, height=675, scale=2)\nfig_tweets_en.write_image(save_path_en, width=1200, height=675, scale=2)\nprint(f\"Saved: {save_path_de.name}\")\nprint(f\"Saved: {save_path_en.name}\")\nfig_tweets_de.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create chart for impressions (bilingual)\nfig_impressions_de = create_keyword_bar_chart(\n    df_keyword_agg,\n    SINGLE_KEYWORD,\n    metric='total_impressions',\n    title=f\"Reichweite von '{SINGLE_KEYWORD}'-Tweets nach Partei\",\n    language='de'\n)\nfig_impressions_en = create_keyword_bar_chart(\n    df_keyword_agg,\n    SINGLE_KEYWORD,\n    metric='total_impressions',\n    title=f\"Reach of '{SINGLE_KEYWORD}' Tweets by Party\",\n    language='en'\n)\n\nsave_path_de = GRAPHICS_DIR / f\"{SINGLE_KEYWORD.lower()}_impressions_by_party_de.png\"\nsave_path_en = GRAPHICS_DIR / f\"{SINGLE_KEYWORD.lower()}_impressions_by_party_en.png\"\nfig_impressions_de.write_image(save_path_de, width=1200, height=675, scale=2)\nfig_impressions_en.write_image(save_path_en, width=1200, height=675, scale=2)\nprint(f\"Saved: {save_path_de.name}\")\nprint(f\"Saved: {save_path_en.name}\")\nfig_impressions_de.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Keyword Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query multiple keywords at once\ndef analyze_multiple_keywords(keywords):\n    \"\"\"\n    Analyze multiple keywords and return comparison data.\n    \"\"\"\n    results = []\n    \n    for keyword in keywords:\n        query = f\"\"\"\n        SELECT\n            '{keyword}' AS keyword,\n            p.partei_kurz AS party,\n            COUNT(*) AS tweet_count,\n            SUM(t.impression_count) AS total_impressions\n        FROM public.tweets t\n        JOIN {POLITICIANS_TABLE} p ON t.username = p.username\n        WHERE t.text ILIKE '%{keyword}%'\n        GROUP BY p.partei_kurz\n        \"\"\"\n        \n        with engine.connect() as conn:\n            df_temp = pd.read_sql(text(query), conn)\n        \n        results.append(df_temp)\n    \n    df_all = pd.concat(results, ignore_index=True)\n    df_all['party_norm'] = df_all['party'].apply(normalize_party)\n    \n    # Aggregate by normalized party\n    df_final = (\n        df_all.groupby(['keyword', 'party_norm'])\n        .agg({'tweet_count': 'sum', 'total_impressions': 'sum'})\n        .reset_index()\n    )\n    \n    return df_final\n\n# Analyze all keywords\nprint(f\"Analyzing {len(KEYWORDS)} keywords...\")\ndf_multi = analyze_multiple_keywords(KEYWORDS)\n\nprint(f\"\\nTotal keyword mentions: {df_multi['tweet_count'].sum():,}\")\nprint(f\"\\nKeyword summary:\")\nkeyword_summary = df_multi.groupby('keyword')['tweet_count'].sum().sort_values(ascending=False)\nprint(keyword_summary)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create grouped bar chart comparing keywords across parties (bilingual)\ndef create_keyword_comparison_chart(df, title=None, language='de'):\n    \"\"\"\n    Create grouped bar chart comparing multiple keywords by party.\n    Supports 'de' (German) and 'en' (English) languages.\n    \"\"\"\n    # Get top parties by total tweets\n    top_parties = (\n        df.groupby('party_norm')['tweet_count']\n        .sum()\n        .nlargest(5)\n        .index.tolist()\n    )\n    \n    df_top = df[df['party_norm'].isin(top_parties)].copy()\n    \n    # Set default title based on language\n    if title is None:\n        title = \"Keyword-Vergleich nach Partei\" if language == 'de' else \"Keyword Comparison by Party\"\n    \n    # Axis labels\n    xaxis_label = \"Partei\" if language == 'de' else \"Party\"\n    yaxis_label = \"Anzahl Tweets\" if language == 'de' else \"Number of Tweets\"\n    legend_title = \"Keywords\"\n    \n    fig = go.Figure()\n    \n    # Add a bar for each keyword\n    colors = px.colors.qualitative.Set2\n    \n    for i, keyword in enumerate(df_top['keyword'].unique()):\n        df_keyword = df_top[df_top['keyword'] == keyword]\n        \n        hover_party = \"Partei\" if language == 'de' else \"Party\"\n        \n        fig.add_trace(go.Bar(\n            name=keyword,\n            x=df_keyword['party_norm'],\n            y=df_keyword['tweet_count'],\n            marker_color=colors[i % len(colors)],\n            text=[f\"{v:,.0f}\" for v in df_keyword['tweet_count']],\n            textposition='outside',\n            hovertemplate=(\n                f\"<b>{keyword}</b><br>\"\n                f\"{hover_party}: %{{x}}<br>\"\n                \"Tweets: %{y:,.0f}<br>\"\n                \"<extra></extra>\"\n            )\n        ))\n    \n    stand_text = get_stand_text(language)\n    title_text = f\"{title}<br><sub style='font-size:0.85em;'>{stand_text}</sub>\"\n    \n    fig.update_layout(\n        title=dict(text=title_text, x=0.5, xanchor='center', font=dict(size=20)),\n        xaxis_title=xaxis_label,\n        yaxis_title=yaxis_label,\n        barmode='group',\n        plot_bgcolor='#1a1a1a',\n        paper_bgcolor='#1a1a1a',\n        font=dict(color='white'),\n        legend=dict(\n            title=legend_title,\n            yanchor=\"top\",\n            y=0.99,\n            xanchor=\"right\",\n            x=0.99,\n            bgcolor='rgba(0,0,0,0.5)'\n        ),\n        margin=dict(l=60, r=40, t=100, b=60),\n        xaxis=dict(gridcolor='#333333'),\n        yaxis=dict(gridcolor='#333333')\n    )\n    \n    return fig\n\n# Create comparison charts in both languages\nfig_comparison_de = create_keyword_comparison_chart(df_multi, language='de')\nfig_comparison_en = create_keyword_comparison_chart(df_multi, language='en')\n\nsave_path_de = GRAPHICS_DIR / \"keywords_comparison_by_party_de.png\"\nsave_path_en = GRAPHICS_DIR / \"keywords_comparison_by_party_en.png\"\nfig_comparison_de.write_image(save_path_de, width=1200, height=675, scale=2)\nfig_comparison_en.write_image(save_path_en, width=1200, height=675, scale=2)\nprint(f\"Saved: {save_path_de.name}\")\nprint(f\"Saved: {save_path_en.name}\")\nfig_comparison_de.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create heatmap of keywords by party (bilingual)\ndef create_keyword_heatmap(df, title=None, language='de'):\n    \"\"\"\n    Create heatmap showing keyword usage intensity by party.\n    Supports 'de' (German) and 'en' (English) languages.\n    \"\"\"\n    # Pivot table for heatmap\n    pivot = df.pivot_table(\n        index='keyword',\n        columns='party_norm',\n        values='tweet_count',\n        fill_value=0\n    )\n    \n    # Sort by total\n    pivot['_total'] = pivot.sum(axis=1)\n    pivot = pivot.sort_values('_total', ascending=False).drop('_total', axis=1)\n    \n    # Set default title based on language\n    if title is None:\n        title = \"Keyword-Heatmap nach Partei\" if language == 'de' else \"Keyword Heatmap by Party\"\n    \n    # Axis labels\n    xaxis_label = \"Partei\" if language == 'de' else \"Party\"\n    yaxis_label = \"Keyword\"\n    colorbar_title = \"Tweets\"\n    \n    fig = go.Figure()\n    \n    fig.add_trace(go.Heatmap(\n        z=pivot.values,\n        x=pivot.columns,\n        y=pivot.index,\n        colorscale='Viridis',\n        text=pivot.values,\n        texttemplate='%{text:.0f}',\n        textfont=dict(color='white', size=12),\n        hovertemplate=(\n            \"Keyword: %{y}<br>\"\n            f\"{xaxis_label}: %{{x}}<br>\"\n            \"Tweets: %{z:,.0f}<br>\"\n            \"<extra></extra>\"\n        ),\n        colorbar=dict(title=colorbar_title)\n    ))\n    \n    stand_text = get_stand_text(language)\n    title_text = f\"{title}<br><sub style='font-size:0.85em;'>{stand_text}</sub>\"\n    \n    fig.update_layout(\n        title=dict(text=title_text, x=0.5, xanchor='center', font=dict(size=20)),\n        xaxis_title=xaxis_label,\n        yaxis_title=yaxis_label,\n        plot_bgcolor='#1a1a1a',\n        paper_bgcolor='#1a1a1a',\n        font=dict(color='white'),\n        margin=dict(l=120, r=100, t=100, b=60),\n        height=max(400, 60 * len(pivot))\n    )\n    \n    return fig\n\n# Create heatmaps in both languages\nfig_heatmap_de = create_keyword_heatmap(df_multi, language='de')\nfig_heatmap_en = create_keyword_heatmap(df_multi, language='en')\n\nsave_path_de = GRAPHICS_DIR / \"keywords_heatmap_de.png\"\nsave_path_en = GRAPHICS_DIR / \"keywords_heatmap_en.png\"\nfig_heatmap_de.write_image(save_path_de, width=1200, height=800, scale=2)\nfig_heatmap_en.write_image(save_path_en, width=1200, height=800, scale=2)\nprint(f\"Saved: {save_path_de.name}\")\nprint(f\"Saved: {save_path_en.name}\")\nfig_heatmap_de.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Tweets for Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get top tweets mentioning the keyword (all variants)\nvariant_conditions = \" OR \".join([f\"t.text ILIKE '%{v}%'\" for v in SINGLE_KEYWORD_VARIANTS])\n\nquery_top_tweets = f\"\"\"\nSELECT\n    t.username,\n    p.partei_kurz AS party,\n    COALESCE(p.vorname || ' ' || p.nachname, t.username) AS full_name,\n    t.text,\n    t.created_at,\n    t.like_count,\n    t.retweet_count,\n    t.impression_count,\n    t.tweet_id\nFROM public.tweets t\nJOIN {POLITICIANS_TABLE} p ON LOWER(t.username) = LOWER(p.username)\nWHERE {variant_conditions}\nORDER BY t.impression_count DESC\nLIMIT 15\n\"\"\"\n\nwith engine.connect() as conn:\n    df_top_tweets = pd.read_sql(text(query_top_tweets), conn)\n\ndf_top_tweets['party_norm'] = df_top_tweets['party'].apply(normalize_party)\n\nprint(f\"\\nTop 15 tweets mentioning '{SINGLE_KEYWORD}' (all variants) by impressions:\\n\")\nfor i, row in df_top_tweets.iterrows():\n    print(f\"{i+1}. @{row['username']} ({row['party_norm']}) - {row['impression_count']:,} impressions\")\n    print(f\"   {row['full_name']} | {row['created_at'].strftime('%Y-%m-%d %H:%M') if row['created_at'] else '?'}\")\n    text_preview = row['text'][:120].replace('\\n', ' ') + ('...' if len(row['text']) > 120 else '')\n    print(f\"   \\\"{text_preview}\\\"\")\n    print(f\"   Likes: {row['like_count']:,} | RTs: {row['retweet_count']:,}\\n\")"
  },
  {
   "cell_type": "markdown",
   "source": "## Timeline: When were Greenland tweets posted?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Timeline analysis - when were Greenland tweets posted? (bilingual)\nvariant_conditions = \" OR \".join([f\"t.text ILIKE '%{v}%'\" for v in SINGLE_KEYWORD_VARIANTS])\n\nquery_timeline = f\"\"\"\nSELECT\n    DATE(t.created_at) AS tweet_date,\n    p.partei_kurz AS party,\n    COUNT(*) AS tweet_count,\n    SUM(t.impression_count) AS total_impressions\nFROM public.tweets t\nJOIN {POLITICIANS_TABLE} p ON LOWER(t.username) = LOWER(p.username)\nWHERE {variant_conditions}\nGROUP BY DATE(t.created_at), p.partei_kurz\nORDER BY tweet_date\n\"\"\"\n\nwith engine.connect() as conn:\n    df_timeline = pd.read_sql(text(query_timeline), conn)\n\ndf_timeline['party_norm'] = df_timeline['party'].apply(normalize_party)\n\n# Aggregate by date and party\ndf_timeline_agg = (\n    df_timeline.groupby(['tweet_date', 'party_norm'])\n    .agg({'tweet_count': 'sum', 'total_impressions': 'sum'})\n    .reset_index()\n)\n\ndef create_timeline_chart(df_timeline_agg, keyword, language='de'):\n    \"\"\"Create timeline chart in specified language.\"\"\"\n    fig = go.Figure()\n    \n    for party in df_timeline_agg['party_norm'].unique():\n        df_party = df_timeline_agg[df_timeline_agg['party_norm'] == party]\n        \n        party_label = \"Partei\" if language == 'de' else \"Party\"\n        date_label = \"Datum\" if language == 'de' else \"Date\"\n        \n        fig.add_trace(go.Scatter(\n            x=df_party['tweet_date'],\n            y=df_party['tweet_count'],\n            mode='lines+markers',\n            name=party,\n            line=dict(color=get_party_color(party), width=2),\n            marker=dict(size=8),\n            hovertemplate=(\n                f\"<b>{party}</b><br>\"\n                f\"{date_label}: %{{x}}<br>\"\n                \"Tweets: %{y}<br>\"\n                \"<extra></extra>\"\n            )\n        ))\n    \n    if language == 'de':\n        title = f\"Timeline: '{keyword}'-Tweets nach Partei\"\n        xaxis_label = \"Datum\"\n        yaxis_label = \"Anzahl Tweets\"\n        legend_title = \"Partei\"\n    else:\n        title = f\"Timeline: '{keyword}' Tweets by Party\"\n        xaxis_label = \"Date\"\n        yaxis_label = \"Number of Tweets\"\n        legend_title = \"Party\"\n    \n    stand_text = get_stand_text(language)\n    title_text = f\"{title}<br><sub style='font-size:0.85em;'>{stand_text}</sub>\"\n    \n    fig.update_layout(\n        title=dict(text=title_text, x=0.5, xanchor='center', font=dict(size=20)),\n        xaxis_title=xaxis_label,\n        yaxis_title=yaxis_label,\n        plot_bgcolor='#1a1a1a',\n        paper_bgcolor='#1a1a1a',\n        font=dict(color='white'),\n        legend=dict(title=legend_title, bgcolor='rgba(0,0,0,0.5)'),\n        margin=dict(l=60, r=40, t=100, b=60),\n        xaxis=dict(gridcolor='#333333'),\n        yaxis=dict(gridcolor='#333333')\n    )\n    \n    return fig\n\n# Create timeline charts in both languages\nfig_timeline_de = create_timeline_chart(df_timeline_agg, SINGLE_KEYWORD, language='de')\nfig_timeline_en = create_timeline_chart(df_timeline_agg, SINGLE_KEYWORD, language='en')\n\nsave_path_de = GRAPHICS_DIR / f\"{SINGLE_KEYWORD.lower()}_timeline_de.png\"\nsave_path_en = GRAPHICS_DIR / f\"{SINGLE_KEYWORD.lower()}_timeline_en.png\"\nfig_timeline_de.write_image(save_path_de, width=1200, height=675, scale=2)\nfig_timeline_en.write_image(save_path_en, width=1200, height=675, scale=2)\nprint(f\"Saved: {save_path_de.name}\")\nprint(f\"Saved: {save_path_en.name}\")\nfig_timeline_de.show()\n\n# Show daily totals\ndaily_totals = df_timeline_agg.groupby('tweet_date')['tweet_count'].sum().reset_index()\nprint(f\"\\nDaily tweet counts for '{SINGLE_KEYWORD}':\")\nfor _, row in daily_totals.iterrows():\n    print(f\"  {row['tweet_date']}: {row['tweet_count']} tweets\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Word Clouds: Most Used Words per Party in Greenland Tweets\n\nVisualizing the most frequently used words in tweets mentioning Greenland, broken down by political party.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Word Cloud Analysis - Most used words per party in Greenland tweets\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport re\n\n# Comprehensive German stopwords to exclude from word clouds\nGERMAN_STOPWORDS = {\n    # Articles\n    'der', 'die', 'das', 'den', 'dem', 'des', 'ein', 'eine', 'einer', 'einem', 'einen', 'eines',\n    # Conjunctions\n    'und', 'oder', 'aber', 'doch', 'wenn', 'weil', 'dass', 'ob', 'als', 'wie', 'so', 'auch',\n    'denn', 'also', 'damit', 'daher', 'deshalb', 'trotzdem', 'jedoch', 'sondern', 'sonst',\n    'weder', 'noch', 'sowohl', 'obwohl', 'falls', 'sofern', 'sobald', 'solange', 'nachdem',\n    'bevor', 'ehe', 'bis', 'seit', 'während', 'indem', 'wobei', 'weshalb', 'weswegen',\n    # Verbs (common)\n    'ist', 'sind', 'war', 'waren', 'wird', 'werden', 'wurde', 'wurden', 'hat', 'haben', 'hatte', 'hatten',\n    'sein', 'bin', 'bist', 'seid', 'gewesen', 'wäre', 'wären', 'sei', 'seien',\n    'habe', 'hast', 'habt', 'gehabt', 'hätte', 'hätten',\n    'werde', 'wirst', 'werdet', 'geworden', 'würde', 'würden',\n    'können', 'kann', 'konnte', 'konnten', 'könnte', 'könnten', 'gekonnt',\n    'müssen', 'muss', 'musste', 'mussten', 'müsste', 'müssten', 'gemusst',\n    'sollen', 'soll', 'sollte', 'sollten', 'gesollt',\n    'wollen', 'will', 'wollte', 'wollten', 'gewollt',\n    'dürfen', 'darf', 'durfte', 'durften', 'dürfte', 'dürften', 'gedurft',\n    'mögen', 'mag', 'mochte', 'mochten', 'möchte', 'möchten', 'gemocht',\n    'gibt', 'geben', 'gab', 'gaben', 'gegeben', 'gäbe', 'gäben',\n    'geht', 'gehen', 'ging', 'gingen', 'gegangen', 'ginge', 'gingen',\n    'kommt', 'kommen', 'kam', 'kamen', 'gekommen', 'käme', 'kämen',\n    'macht', 'machen', 'machte', 'machten', 'gemacht',\n    'sagt', 'sagen', 'sagte', 'sagten', 'gesagt',\n    'lässt', 'lassen', 'ließ', 'ließen', 'gelassen',\n    'bleibt', 'bleiben', 'blieb', 'blieben', 'geblieben',\n    'steht', 'stehen', 'stand', 'standen', 'gestanden',\n    'nimmt', 'nehmen', 'nahm', 'nahmen', 'genommen',\n    'findet', 'finden', 'fand', 'fanden', 'gefunden',\n    'weiß', 'wissen', 'wusste', 'wussten', 'gewusst',\n    'sieht', 'sehen', 'sah', 'sahen', 'gesehen',\n    'heißt', 'heißen', 'hieß', 'hießen', 'geheißen',\n    'braucht', 'brauchen', 'brauchte', 'brauchten', 'gebraucht',\n    'scheint', 'scheinen', 'schien', 'schienen', 'geschienen',\n    'meint', 'meinen', 'meinte', 'meinten', 'gemeint',\n    'denkt', 'denken', 'dachte', 'dachten', 'gedacht',\n    'glaubt', 'glauben', 'glaubte', 'glaubten', 'geglaubt',\n    'zeigt', 'zeigen', 'zeigte', 'zeigten', 'gezeigt',\n    'tut', 'tun', 'tat', 'taten', 'getan',\n    # Pronouns\n    'ich', 'du', 'er', 'sie', 'es', 'wir', 'ihr', 'sie', 'Sie',\n    'mich', 'dich', 'ihn', 'uns', 'euch', 'sich',\n    'mir', 'dir', 'ihm', 'ihr', 'ihnen', 'Ihnen',\n    'mein', 'meine', 'meiner', 'meinem', 'meinen', 'meines',\n    'dein', 'deine', 'deiner', 'deinem', 'deinen', 'deines',\n    'sein', 'seine', 'seiner', 'seinem', 'seinen', 'seines',\n    'ihr', 'ihre', 'ihrer', 'ihrem', 'ihren', 'ihres',\n    'unser', 'unsere', 'unserer', 'unserem', 'unseren', 'unseres',\n    'euer', 'eure', 'eurer', 'eurem', 'euren', 'eures',\n    'man', 'selbst', 'selber', 'einander',\n    # Demonstratives/Relatives\n    'dieser', 'diese', 'dieses', 'diesem', 'diesen',\n    'jener', 'jene', 'jenes', 'jenem', 'jenen',\n    'jeder', 'jede', 'jedes', 'jedem', 'jeden',\n    'welcher', 'welche', 'welches', 'welchem', 'welchen',\n    'solcher', 'solche', 'solches', 'solchem', 'solchen',\n    'derjenige', 'diejenige', 'dasjenige',\n    'derselbe', 'dieselbe', 'dasselbe',\n    # Prepositions\n    'bei', 'mit', 'nach', 'von', 'vor', 'zu', 'zum', 'zur', 'aus', 'auf', 'an', 'in', 'im', 'am', 'um', 'für',\n    'über', 'unter', 'durch', 'gegen', 'ohne', 'bis', 'seit', 'während', 'wegen', 'trotz', 'statt', 'anstatt',\n    'außer', 'binnen', 'entlang', 'gegenüber', 'gemäß', 'hinter', 'infolge', 'innerhalb', 'jenseits',\n    'laut', 'mittels', 'neben', 'oberhalb', 'seitens', 'unterhalb', 'unweit', 'zwischen',\n    'ab', 'außerhalb', 'diesseits', 'entgegen', 'entsprechend', 'längs', 'zufolge', 'zugunsten',\n    # Adverbs\n    'nicht', 'noch', 'schon', 'nur', 'sehr', 'mehr', 'viel', 'wenig', 'ganz', 'gar', 'fast', 'kaum',\n    'hier', 'dort', 'da', 'dann', 'wann', 'wo', 'wohin', 'woher', 'hin', 'her',\n    'jetzt', 'heute', 'morgen', 'gestern', 'immer', 'nie', 'niemals', 'oft', 'mal', 'wieder',\n    'nun', 'bereits', 'bald', 'eben', 'gerade', 'gleich', 'sofort', 'endlich', 'zuerst', 'zuletzt',\n    'oben', 'unten', 'vorne', 'hinten', 'links', 'rechts', 'innen', 'außen',\n    'irgendwo', 'irgendwie', 'irgendwann', 'irgendwas', 'irgendwer', 'nirgends', 'nirgendwo',\n    'etwa', 'ungefähr', 'circa', 'rund', 'ziemlich', 'genug', 'besonders', 'sogar', 'wohl',\n    'eher', 'etwas', 'meist', 'meistens', 'manchmal', 'selten', 'stets', 'überhaupt',\n    'außerdem', 'dennoch', 'hingegen', 'insbesondere', 'jedenfalls', 'nämlich', 'übrigens',\n    # Interrogatives\n    'was', 'wer', 'wen', 'wem', 'wessen', 'warum', 'wieso', 'weshalb', 'weswegen', 'wie', 'wieviel', 'wieviele',\n    # Negation/Indefinites\n    'kein', 'keine', 'keiner', 'keinem', 'keinen', 'keines', 'nichts', 'niemand', 'niemanden', 'niemandem',\n    'alle', 'alles', 'allem', 'allen', 'aller',\n    'andere', 'anderer', 'anderen', 'anderem', 'anderes', 'anders',\n    'einige', 'einiger', 'einigen', 'einigem', 'einiges',\n    'etliche', 'etlicher', 'etlichen', 'etlichem', 'etliches',\n    'manche', 'mancher', 'manchen', 'manchem', 'manches',\n    'mehrere', 'mehrerer', 'mehreren', 'mehrerem',\n    'viele', 'vieler', 'vielen', 'vielem', 'vieles',\n    'wenige', 'weniger', 'wenigen', 'wenigem', 'weniges',\n    'beide', 'beider', 'beiden', 'beidem', 'beides',\n    'sämtliche', 'sämtlicher', 'sämtlichen', 'sämtlichem', 'sämtliches',\n    # Numbers/Ordinals\n    'eins', 'zwei', 'drei', 'vier', 'fünf', 'sechs', 'sieben', 'acht', 'neun', 'zehn',\n    'erste', 'ersten', 'erster', 'erstes', 'zweite', 'zweiten', 'zweiter', 'dritten',\n    # Common filler words\n    'ja', 'nein', 'doch', 'wohl', 'halt', 'eben', 'mal', 'schließlich', 'eigentlich', 'letztlich',\n    'natürlich', 'tatsächlich', 'wirklich', 'wahrscheinlich', 'möglicherweise', 'vermutlich',\n    'vielleicht', 'bestimmt', 'sicher', 'sicherlich', 'gewiss', 'offenbar', 'anscheinend',\n    # Abbreviations and Twitter-specific\n    'bzw', 'etc', 'zb', 'usw', 'co', 'rt', 'via', 'https', 'http', 'amp', 'www', 'de', 'com', 'org',\n    # English stopwords (common in German tweets)\n    'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can', 'had', 'her', 'was', 'one', 'our',\n    'out', 'day', 'get', 'has', 'him', 'his', 'how', 'its', 'may', 'new', 'now', 'old', 'see', 'way',\n    'who', 'boy', 'did', 'own', 'say', 'she', 'too', 'use', 'with', 'this', 'that', 'from', 'have',\n    'will', 'your', 'more', 'when', 'what', 'been', 'some', 'them', 'than', 'only', 'come', 'over',\n    'such', 'into', 'year', 'just', 'know', 'take', 'people', 'into', 'year', 'good', 'could',\n    'be', 'to', 'of', 'in', 'it', 'is', 'on', 'at', 'as', 'by', 'we', 'or', 'an', 'no', 'if', 'so',\n}\n\n# Additional Twitter-specific words to exclude\nTWITTER_STOPWORDS = {'rt', 'https', 'http', 'co', 't', 'amp', 'via', 'twitter', 'tweet', 'tweets', 'x'}\n\n# Combine all stopwords\nALL_STOPWORDS = GERMAN_STOPWORDS | TWITTER_STOPWORDS | set(v.lower() for v in SINGLE_KEYWORD_VARIANTS)\n\ndef clean_text_for_wordcloud(text: str) -> str:\n    \"\"\"Clean tweet text for word cloud generation.\"\"\"\n    if not text:\n        return \"\"\n    # Remove URLs\n    text = re.sub(r'https?://\\S+', '', text)\n    # Remove mentions\n    text = re.sub(r'@\\w+', '', text)\n    # Remove hashtag symbols but keep the word\n    text = re.sub(r'#(\\w+)', r'\\1', text)\n    # Remove special characters, keep letters and German umlauts\n    text = re.sub(r'[^\\w\\sÄäÖöÜüß]', ' ', text)\n    # Remove numbers\n    text = re.sub(r'\\d+', '', text)\n    # Convert to lowercase\n    text = text.lower()\n    # Remove extra whitespace\n    text = ' '.join(text.split())\n    return text\n\ndef get_wordcloud_color_for_party(party: str) -> str:\n    \"\"\"Get word cloud color for a party - use actual party colors, white for CDU/CSU.\"\"\"\n    normalized = normalize_party(party)\n    \n    # Special case: CDU/CSU uses white instead of black for visibility on dark background\n    if normalized == \"CDU/CSU\":\n        return '#FFFFFF'\n    \n    # Use actual party colors for all other parties\n    return PARTY_COLORS.get(normalized, '#888888')\n\ndef create_party_wordcloud(party_name: str, texts: list, keyword: str):\n    \"\"\"Create a word cloud for a specific party's tweets.\"\"\"\n    # Combine all texts\n    combined_text = ' '.join([clean_text_for_wordcloud(t) for t in texts if t])\n    \n    # Filter out stopwords and short words\n    words = combined_text.split()\n    filtered_words = [w for w in words if w not in ALL_STOPWORDS and len(w) > 2]\n    filtered_text = ' '.join(filtered_words)\n    \n    if not filtered_text.strip():\n        return None\n    \n    # Get the party color for the word cloud\n    wc_color = get_wordcloud_color_for_party(party_name)\n    \n    # Create color function\n    def party_color_func(*args, **kwargs):\n        return wc_color\n    \n    # Generate word cloud\n    wc = WordCloud(\n        width=800,\n        height=400,\n        background_color='#1a1a1a',\n        color_func=party_color_func,\n        max_words=50,\n        min_font_size=10,\n        max_font_size=100,\n        relative_scaling=0.5,\n        collocations=False,  # Don't include word pairs\n    ).generate(filtered_text)\n    \n    return wc\n\n# Query all tweets with text for word cloud\nvariant_conditions = \" OR \".join([f\"t.text ILIKE '%{v}%'\" for v in SINGLE_KEYWORD_VARIANTS])\n\nquery_wordcloud = f\"\"\"\nSELECT\n    t.text,\n    p.partei_kurz AS party\nFROM public.tweets t\nJOIN {POLITICIANS_TABLE} p ON LOWER(t.username) = LOWER(p.username)\nWHERE {variant_conditions}\n\"\"\"\n\nwith engine.connect() as conn:\n    df_wordcloud = pd.read_sql(text(query_wordcloud), conn)\n\ndf_wordcloud['party_norm'] = df_wordcloud['party'].apply(normalize_party)\n\n# Get parties with enough tweets\nparty_counts = df_wordcloud['party_norm'].value_counts()\nparties_to_plot = party_counts[party_counts >= 3].index.tolist()\n\nprint(f\"Creating word clouds for {len(parties_to_plot)} parties with 3+ tweets:\")\nfor p in parties_to_plot:\n    color = get_wordcloud_color_for_party(p)\n    print(f\"  - {p}: {party_counts[p]} tweets (color: {color})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Generate and display word clouds for each party (bilingual)\ndef create_combined_wordcloud_figure(parties_to_plot, df_wordcloud, keyword, language='de'):\n    \"\"\"Create combined word cloud figure for all parties.\"\"\"\n    n_parties = len(parties_to_plot)\n    if n_parties == 0:\n        print(\"No parties with enough tweets for word clouds\")\n        return None\n    \n    # Create a grid of subplots\n    n_cols = 2\n    n_rows = (n_parties + 1) // 2\n    \n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 5 * n_rows))\n    fig.patch.set_facecolor('#1a1a1a')\n    \n    # Flatten axes for easier iteration\n    if n_parties == 1:\n        axes = [axes]\n    else:\n        axes = axes.flatten()\n    \n    # Subtitle text based on language\n    tweets_label = \"Tweets\" if language == 'de' else \"Tweets\"\n    no_words_text = \"Nicht genug Wörter\" if language == 'de' else \"Not enough words\"\n    \n    for idx, party in enumerate(parties_to_plot):\n        ax = axes[idx]\n        ax.set_facecolor('#1a1a1a')\n        \n        # Get tweets for this party\n        party_texts = df_wordcloud[df_wordcloud['party_norm'] == party]['text'].tolist()\n        display_color = get_wordcloud_color_for_party(party)  # Use party color for title\n        \n        # Create word cloud\n        wc = create_party_wordcloud(party, party_texts, keyword)\n        \n        if wc:\n            ax.imshow(wc, interpolation='bilinear')\n            # Party name in party color, larger and bold\n            ax.set_title(f\"{party}\\n\", color=display_color, fontsize=22, fontweight='bold', pad=5)\n            # Add tweet count as smaller subtitle\n            ax.text(0.5, 1.02, f\"({len(party_texts)} {tweets_label})\", \n                   transform=ax.transAxes, ha='center', va='bottom',\n                   color='#888888', fontsize=12)\n        else:\n            ax.text(0.5, 0.5, f\"{no_words_text}\\n{party}\", \n                   ha='center', va='center', color='white', fontsize=14)\n            ax.set_title(f\"{party}\", color=display_color, fontsize=22, fontweight='bold')\n        \n        ax.axis('off')\n    \n    # Hide unused subplots\n    for idx in range(n_parties, len(axes)):\n        axes[idx].set_visible(False)\n    \n    # Main title based on language\n    if language == 'de':\n        main_title = f\"Word Clouds: '{keyword}'-Tweets nach Partei\"\n    else:\n        main_title = f\"Word Clouds: '{keyword}' Tweets by Party\"\n    \n    stand_text = get_stand_text(language)\n    fig.suptitle(f\"{main_title}\\n{stand_text}\", \n                color='white', fontsize=24, fontweight='bold', y=1.02)\n    \n    plt.tight_layout()\n    return fig\n\n# Create combined word clouds in both languages\nn_parties = len(parties_to_plot)\nif n_parties > 0:\n    # German version\n    fig_wc_de = create_combined_wordcloud_figure(parties_to_plot, df_wordcloud, SINGLE_KEYWORD, language='de')\n    save_path_de = GRAPHICS_DIR / f\"{SINGLE_KEYWORD.lower()}_wordclouds_all_parties_de.png\"\n    if fig_wc_de:\n        fig_wc_de.savefig(save_path_de, dpi=150, bbox_inches='tight', facecolor='#1a1a1a', edgecolor='none')\n        print(f\"Saved: {save_path_de.name}\")\n        plt.close(fig_wc_de)\n    \n    # English version\n    fig_wc_en = create_combined_wordcloud_figure(parties_to_plot, df_wordcloud, SINGLE_KEYWORD, language='en')\n    save_path_en = GRAPHICS_DIR / f\"{SINGLE_KEYWORD.lower()}_wordclouds_all_parties_en.png\"\n    if fig_wc_en:\n        fig_wc_en.savefig(save_path_en, dpi=150, bbox_inches='tight', facecolor='#1a1a1a', edgecolor='none')\n        print(f\"Saved: {save_path_en.name}\")\n        plt.show()\nelse:\n    print(\"No parties with enough tweets for word clouds\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Save individual word clouds per party (for social media) - bilingual\nprint(\"\\nSaving individual word clouds per party (DE + EN)...\")\n\nfor party in parties_to_plot:\n    party_texts = df_wordcloud[df_wordcloud['party_norm'] == party]['text'].tolist()\n    display_color = get_wordcloud_color_for_party(party)  # Use party color for title\n    \n    wc = create_party_wordcloud(party, party_texts, SINGLE_KEYWORD)\n    \n    if wc:\n        # Sanitize party name for filename\n        party_filename = party.replace('/', '_').replace(' ', '_').replace('.', '')\n        \n        # German version\n        fig_single_de, ax_single_de = plt.subplots(figsize=(12, 6))\n        fig_single_de.patch.set_facecolor('#1a1a1a')\n        ax_single_de.set_facecolor('#1a1a1a')\n        ax_single_de.imshow(wc, interpolation='bilinear')\n        \n        # Create two-line title: party name in color, details in gray\n        ax_single_de.set_title(f\"{party}\", color=display_color, fontsize=24, fontweight='bold', pad=15, loc='center')\n        ax_single_de.text(0.5, 1.01, f\"'{SINGLE_KEYWORD}'-Tweets ({len(party_texts)} Tweets) | {get_stand_text('de')}\", \n                         transform=ax_single_de.transAxes, ha='center', va='bottom',\n                         color='#888888', fontsize=12)\n        ax_single_de.axis('off')\n        \n        save_path_de = GRAPHICS_DIR / f\"{SINGLE_KEYWORD.lower()}_wordcloud_{party_filename}_de.png\"\n        fig_single_de.savefig(save_path_de, dpi=150, bbox_inches='tight', facecolor='#1a1a1a', edgecolor='none')\n        plt.close(fig_single_de)\n        \n        # English version\n        fig_single_en, ax_single_en = plt.subplots(figsize=(12, 6))\n        fig_single_en.patch.set_facecolor('#1a1a1a')\n        ax_single_en.set_facecolor('#1a1a1a')\n        ax_single_en.imshow(wc, interpolation='bilinear')\n        \n        # Create two-line title: party name in color, details in gray\n        ax_single_en.set_title(f\"{party}\", color=display_color, fontsize=24, fontweight='bold', pad=15, loc='center')\n        ax_single_en.text(0.5, 1.01, f\"'{SINGLE_KEYWORD}' Tweets ({len(party_texts)} Tweets) | {get_stand_text('en')}\", \n                         transform=ax_single_en.transAxes, ha='center', va='bottom',\n                         color='#888888', fontsize=12)\n        ax_single_en.axis('off')\n        \n        save_path_en = GRAPHICS_DIR / f\"{SINGLE_KEYWORD.lower()}_wordcloud_{party_filename}_en.png\"\n        fig_single_en.savefig(save_path_en, dpi=150, bbox_inches='tight', facecolor='#1a1a1a', edgecolor='none')\n        plt.close(fig_single_en)\n        \n        print(f\"  {party}: {save_path_de.name}, {save_path_en.name}\")\n\nprint(f\"\\nIndividual word clouds saved to {GRAPHICS_DIR}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\nprint(f\"\\n{'='*80}\")\nprint(f\"Keyword Analysis Complete!\")\nprint(f\"{'='*80}\\n\")\n\nprint(f\"Analyzed keyword: {SINGLE_KEYWORD}\")\nprint(f\"Additional keywords: {', '.join(KEYWORDS)}\\n\")\n\nprint(f\"Charts saved to: {GRAPHICS_DIR}\\n\")\n\n# List all PNG files\npng_files = sorted(GRAPHICS_DIR.glob(\"*.png\"))\n\n# Separate DE and EN files\nde_files = [f for f in png_files if '_de.png' in f.name]\nen_files = [f for f in png_files if '_en.png' in f.name]\n\nprint(f\"German charts (_de.png): {len(de_files)}\")\nfor png_file in de_files:\n    size = os.path.getsize(png_file) / 1024\n    print(f\"  {png_file.name} ({size:.1f} KB)\")\n\nprint(f\"\\nEnglish charts (_en.png): {len(en_files)}\")\nfor png_file in en_files:\n    size = os.path.getsize(png_file) / 1024\n    print(f\"  {png_file.name} ({size:.1f} KB)\")\n\nprint(f\"\\n{len(png_files)} chart(s) ready for social media posting (bilingual)!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xminer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}